{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiac-superintendent",
   "metadata": {},
   "source": [
    "# Manipulating fMRI data and computing a connectome\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "For this tutorial, we will use the data provided by the `nilearn.datasets` module.\n",
    "We first download some fMRI data from 1 subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "data_dir = None # change this variable with the path where you want nilearn to download\n",
    "                # the data, if you leave None, the default will be '~/nilearn_data'\n",
    "    \n",
    "# Loading the functional datasets\n",
    "data = datasets.fetch_development_fmri(n_subjects=1, data_dir=data_dir)\n",
    "\n",
    "# you can use the .keys() method to check what's in the dataset\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the description of the dataset to know what we're dealing with \n",
    "print(data.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.func contains the paths to the Nifti files (the files containing fMRI data)\n",
    "fmri_filepath = data.func[0]\n",
    "print(fmri_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load a Nifti file with the nibabel library\n",
    "import nibabel as nib\n",
    "\n",
    "fmri_img = nib.load(fmri_filepath)\n",
    "print(fmri_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-express",
   "metadata": {},
   "source": [
    "So this is a `Nifti1Image` object which contains 3 things :\n",
    "* some data of shape (50, 59, 50, 168)\n",
    "* an affine array that defines the spatial orientation and scale of the data\n",
    "* a header, containing more information about the data format\n",
    "\n",
    "Note that the data is a 4D array. The last dimension is the time, so we have 168 volumes, and from the 5th value of the pixdim array in the header we can see that the t_r is 1s, so we have a file that represents 168s of scanning. \n",
    "\n",
    "For each time point we have a 3D array that contains the voxels. But not all these voxels correspond to the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the data array \n",
    "fmri_data = fmri_img.get_fdata()\n",
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-damage",
   "metadata": {},
   "source": [
    "We can choose a voxel (for example the one with coordinates 25, 30, 25) and plot its time series :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(fmri_data[25,30,25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-silicon",
   "metadata": {},
   "source": [
    "We can also plot a slice of our brain for a time point as an image, for example a transversal slice for the first time point and z=25 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fmri_data[:,:,25,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-suite",
   "metadata": {},
   "source": [
    "Here all the black pixels in our image are voxels present in our `fmri_data` array but not containing any brain. Thus we want to exclude all these empty voxels just to keep the ones containing brain data. To do that we're gonna use a **masker**. \n",
    "\n",
    "## Masking the data\n",
    "\n",
    "The masker not only removes the background voxels, but it can also regress out the confounds if you provide them.\n",
    "\n",
    "In short, the confounds are external sources of signal you want to remove, such as the movement of the head. Regressing out the confounds means removing the part of the signal correlated to the sources of noise. For example we can remove the part of the signal that correlates with the head motion because we consider this part of signal to be only artefacts caused by the movements and not relevant for brain activity. \n",
    "\n",
    "Confounds handling is in reality more complicated than that, if you want to learn more you can check the [fMRIprep documentation](https://fmriprep.org/en/stable/outputs.html#confounds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "masker = NiftiMasker()\n",
    "masked_data = masker.fit_transform(fmri_filepath, confounds=data.confounds)\n",
    "masked_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-vertical",
   "metadata": {},
   "source": [
    "Now you see that our array has a different shape, we have our time dimension first with still 168 time points, but for each time point, instead of a 3D volume, we have a 1D array. \n",
    "\n",
    "Also note that we kept 32,504 voxels, when whe had a total of 50*59*50 = 147,500, so we got rid of a lot of empty voxels. That is good, but the downside is that we lost the spatial information of where these voxels are in the brain. But don't worry because the masker remembers it. If we want to recover this information and turn back our 1D arrays into 3D spatial ones we can uste the `makser.inverse_transform` method.\n",
    "\n",
    "For example if we want to threshold our fMRI data by the mean and then plot ther result we can do it this way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_masked_data = masked_data * (masked_data > masked_data.mean())\n",
    "\n",
    "thresholded_img = masker.inverse_transform(thresholded_masked_data)\n",
    "\n",
    "plt.imshow(thresholded_img.get_fdata()[:,:,25,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-anthony",
   "metadata": {},
   "source": [
    "**NOTE**: In this example we instantiated a `NiftiMasker` without providing any argument, \n",
    "however depending on the data used, we might want to use specific strategies to remove the\n",
    "background voxels, and we can ask the masker to do some complementrary processing such as \n",
    "standardizing the data, deterending it or resampleing it. In real-life use cases you should carefully \n",
    "choose the arguments to provide to the `NiftiMasker`. These arguments are explained in \n",
    "the [nilearn documentation](https://nilearn.github.io/modules/generated/nilearn.input_data.NiftiMasker.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-supervision",
   "metadata": {},
   "source": [
    "## Using an atlas\n",
    "\n",
    "Having removed the empty voxels is great, and we could directly compute a connectome on the masked data,\n",
    "but it would create a 32,504 by 32,504 matrix, which would be a bit hard to analyse.\n",
    "\n",
    "An easier way to manipulate the data would be to use an atlas, that defines region of interest (ROIs). We could create our own atlas by clustering the voxels, but hopefully nilearn provides ready-made atlases, let's load one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_dataset = datasets.fetch_atlas_msdl(data_dir=data_dir)\n",
    "atlas_filepath = atlas_dataset.maps\n",
    "labels = atlas_dataset.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-peripheral",
   "metadata": {},
   "source": [
    "We now have the path to the Nifti file containing the ROIs info in `atlas_filepath` and the names of the ROIs in `labels`.\n",
    "\n",
    "To apply the atlas on our data, we can once again use a masker, bu this time a `NiftiMapsMasker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMapsMasker\n",
    "\n",
    "atlas_masker = NiftiMapsMasker(maps_img=atlas_filepath, standardize=True)\n",
    "\n",
    "data_in_atlas = atlas_masker.fit_transform(fmri_filepath, confounds=data.confounds)\n",
    "data_in_atlas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-right",
   "metadata": {},
   "source": [
    "We see that now we only have 39 values per time point, so we have 39 ROIs. This is more appropriate to compute a connectivity matrix.\n",
    "\n",
    "We can plot the time series in a ROI (for example the 5th one) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_in_atlas[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-carry",
   "metadata": {},
   "source": [
    "**Note**: Depending on the type of atlas you use, you might have to use different kinds of masker. Here we have probabilistic overlapping regions, so we use a `NiftiMapsMasker`, but if we had non-overlapping regions, we would use a `NiftiLabelsMasker`.\n",
    "\n",
    "## Connectome\n",
    "\n",
    "Let's compute and plot a correlation matrix !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "correlation_matrix = correlation_measure.fit_transform([data_in_atlas])[0]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "import numpy as np\n",
    "from nilearn import plotting\n",
    "# Make a large figure\n",
    "# Mask the main diagonal for visualization:\n",
    "np.fill_diagonal(correlation_matrix, 0)\n",
    "# The matrix is reordered for block-like representation\n",
    "plotting.plot_matrix(correlation_matrix, figure=(10, 8), labels=labels,\n",
    "                     vmax=0.8, vmin=-0.8, reorder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-court",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Earlier we simply plotted a slice of our brain with matplotlib. It works and it is a fine way to check your data array. However for more complex or fancy plots, nilearn comes with a lot of handy tools in its `nilearn.plotting` module. Here are a few examples.\n",
    "\n",
    "* To view a 3D NiftiImage object, the `view_img` functions makes it easy to interactively go through the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import view_img\n",
    "\n",
    "# Since our fmri_img is a 4D NiftiImage, we need to generate a 3D one.\n",
    "# One way of doing that is averaging our volumes on the time axis \n",
    "# with the mean_img function.\n",
    "from nilearn.image.image import mean_img\n",
    "\n",
    "fmri_img_mean = mean_img(fmri_img)\n",
    "view_img(fmri_img_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-interval",
   "metadata": {},
   "source": [
    "* To display the graph corresponding to a connectome, you can use `plot_connectome`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_connectome\n",
    "\n",
    "coords = atlas_dataset.region_coords\n",
    "\n",
    "# We threshold to keep only the 10% of edges with the highest value\n",
    "# because the graph is very dense\n",
    "plot_connectome(correlation_matrix, coords,\n",
    "                edge_threshold=\"90%\", colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-actress",
   "metadata": {},
   "source": [
    "To discover more ways of generating super cool visuals of brains, check the [nilearn plotting documentation](https://nilearn.github.io/plotting/index.html).\n",
    "\n",
    "# Exercises\n",
    "\n",
    "## 1. Of the importance of confounds\n",
    "\n",
    "* Generate a correlation matrix with the same data, but this time without using the confounds when masking.\n",
    "\n",
    "How does that impact the correlation matrix ?\n",
    "Why do you think it affects the matrix this way ?\n",
    "\n",
    "* Plot the obtained connectome in 3D using `nilearn.plotting.view_connectome` (check [the doc](https://nilearn.github.io/modules/generated/nilearn.plotting.view_connectome.html) to know how to use it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-salmon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "primary-mapping",
   "metadata": {},
   "source": [
    "## 2. Visualizing the atlas and a specific time point\n",
    "\n",
    "* Use `view_img` to visualize the 5th ROI of the atlas. (Hint: use the atlas masker to inverse transform an array with 1 at the index 4 and 0 every where else.)\n",
    "\n",
    "* Use `plotting.plot_prob_atlas` to show all the ROIs with filled contours. (Hint: check the nilearn documentation to see how to use `plotting.plot_prob_atlas`).\n",
    "* Earlier we used `view_img` to plot the mean volume of our `fmri_img` data because `view_img` doesn't accept 4D images but only 3D ones. Find a way to generate a 3D Nifti image with the 84th time point in `fmri_img` and plot it with `view_img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-module",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "determined-venue",
   "metadata": {},
   "source": [
    "## 3. Seed-based connectivity\n",
    "\n",
    "* Using the information provided in [this nilearn tutorial](https://nilearn.github.io/stable/auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html), plot the seed-to-voxel correlation map of our fmri_img for the seed of coordinates (-16, -74, 7) and with a sphere mask of radius of size 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_coords = [(-16, -74, 7)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
